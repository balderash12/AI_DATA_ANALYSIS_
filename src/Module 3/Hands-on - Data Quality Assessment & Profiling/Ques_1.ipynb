{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1: Load a CSV Dataset\n",
    "# Description: Load a CSV file into a Pandas DataFrame and print the first five rows to understand the structure of the dataset.\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load dataset once for all tasks\n",
    "def load_data(file_path):\n",
    "    \"\"\"Load dataset with error handling.\"\"\"\n",
    "    try:\n",
    "        if not os.path.exists(file_path):\n",
    "            raise FileNotFoundError(f\"Error: The file '{file_path}' does not exist.\")\n",
    "        \n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Check for empty dataset\n",
    "        if df.empty:\n",
    "            raise ValueError(\"Error: The dataset is empty.\")\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "# Task 1: Display first five rows\n",
    "def preview_data(df):\n",
    "    \"\"\"Preview first five rows of dataset.\"\"\"\n",
    "    print(\"\\nDataset Preview:\")\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2: Check for missing values\n",
    "def check_missing_values(df):\n",
    "    \"\"\"Identify columns with missing values.\"\"\"\n",
    "    missing_columns = df.isnull().sum()[df.isnull().sum() > 0]\n",
    "    print(\"\\nColumns with missing values:\")\n",
    "    print(missing_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3: Visualize missing data\n",
    "def visualize_missing_data(df):\n",
    "    \"\"\"Generate heatmap for missing values.\"\"\"\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.heatmap(df.isnull(), cmap=\"coolwarm\", cbar=False)\n",
    "    plt.title(\"Missing Data Heatmap\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 4: Remove columns with >50% missing values\n",
    "def remove_high_missing_columns(df):\n",
    "    \"\"\"Drop columns with over 50% missing values.\"\"\"\n",
    "    threshold = len(df) * 0.5\n",
    "    df_cleaned = df.dropna(thresh=threshold, axis=1)\n",
    "    print(\"\\nRemaining Columns After Removal:\")\n",
    "    print(df_cleaned.columns)\n",
    "    return df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 5: Identify duplicate rows\n",
    "def find_duplicates(df):\n",
    "    \"\"\"Find duplicate rows.\"\"\"\n",
    "    duplicates = df[df.duplicated()]\n",
    "    if not duplicates.empty:\n",
    "        print(\"\\nDuplicate rows found:\")\n",
    "        print(duplicates)\n",
    "    else:\n",
    "        print(\"\\nNo duplicate rows found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 6: Remove duplicate rows\n",
    "def remove_duplicates(df):\n",
    "    \"\"\"Remove duplicate rows and verify removal.\"\"\"\n",
    "    df_cleaned = df.drop_duplicates()\n",
    "    remaining_duplicates = df_cleaned.duplicated().sum()\n",
    "    print(f\"\\nDuplicate rows remaining after cleanup: {remaining_duplicates}\")\n",
    "    return df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 7: Check data inconsistencies\n",
    "def check_inconsistencies(df):\n",
    "    \"\"\"Detect inconsistencies in categorical columns.\"\"\"\n",
    "    categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "    for col in categorical_cols:\n",
    "        df[col] = df[col].astype(str)\n",
    "        inconsistent_rows = df[(df[col] != df[col].str.strip()) | (df[col] != df[col].str.lower())]\n",
    "        if not inconsistent_rows.empty:\n",
    "            print(f\"\\nInconsistencies in '{col}':\")\n",
    "            print(inconsistent_rows[[col]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 8: Get summary of data quality\n",
    "def data_quality_summary(df):\n",
    "    \"\"\"Generate data quality summary.\"\"\"\n",
    "    summary = {\n",
    "        \"Total Records\": len(df),\n",
    "        \"Duplicate Rows\": df.duplicated().sum(),\n",
    "        \"Missing Values\": df.isnull().sum()[df.isnull().sum() > 0].to_dict()\n",
    "    }\n",
    "    print(\"\\nData Quality Summary:\")\n",
    "    print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 9: Generate a data quality report\n",
    "def data_quality_report(df):\n",
    "    \"\"\"Generate full data quality report with basic stats and distributions.\"\"\"\n",
    "    report = {\n",
    "        \"Total Records\": len(df),\n",
    "        \"Duplicate Rows\": df.duplicated().sum(),\n",
    "        \"Missing Values\": df.isnull().sum()[df.isnull().sum() > 0].to_dict(),\n",
    "        \"Numerical Summary\": df.describe().to_dict(),\n",
    "        \"Categorical Distributions\": {col: df[col].value_counts().to_dict() for col in df.select_dtypes(include=['object']).columns}\n",
    "    }\n",
    "    import pprint\n",
    "    pprint.pprint(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: The file 'your_dataset.csv' does not exist.\n",
      "Data loading failed. Process terminated.\n"
     ]
    }
   ],
   "source": [
    "# Task 10: Advanced Data Imputation\n",
    "def impute_missing_data(df):\n",
    "    \"\"\"Impute missing values (numerical: mean, categorical: mode) and verify.\"\"\"\n",
    "    numerical_cols = df.select_dtypes(include=['number']).columns\n",
    "    df[numerical_cols] = df[numerical_cols].apply(lambda col: col.fillna(col.mean()))\n",
    "\n",
    "    categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "    df[categorical_cols] = df[categorical_cols].apply(lambda col: col.fillna(col.mode()[0] if not col.mode().empty else col))\n",
    "\n",
    "    # Verify imputation success\n",
    "    if df.isnull().sum().sum() == 0:\n",
    "        print(\"\\nImputation successful: No missing values remain.\")\n",
    "    else:\n",
    "        print(\"\\nWarning: Some missing values still exist.\")\n",
    "\n",
    "    return df\n",
    "\n",
    "# Main execution\n",
    "file_path = \"your_dataset.csv\"\n",
    "df = load_data(file_path)\n",
    "\n",
    "if df is not None:\n",
    "    preview_data(df)\n",
    "    check_missing_values(df)\n",
    "    visualize_missing_data(df)\n",
    "    df = remove_high_missing_columns(df)\n",
    "    find_duplicates(df)\n",
    "    df = remove_duplicates(df)\n",
    "    check_inconsistencies(df)\n",
    "    data_quality_summary(df)\n",
    "    data_quality_report(df)\n",
    "    df = impute_missing_data(df)\n",
    "else:\n",
    "    print(\"Data loading failed. Process terminated.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
